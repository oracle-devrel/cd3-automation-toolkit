#!/bin/python
import oci
import pandas as pd
import configparser
import datetime
import json
import os
import argparse
from oci.object_storage.object_storage_client import ObjectStorageClient
from oci.object_storage.models import CreatePreauthenticatedRequestDetails



parser = argparse.ArgumentParser(description="Creates Panda related config files")
parser.add_argument("tfstatefile",help="The terraform.tfstate file after panda has been instantiated")
parser.add_argument("koala_export_file",help="Path to the instances export of Koala")
parser.add_argument("koala_resource_file",help="Path to resources-default.json - export from Koala")
parser.add_argument("xlfile", help="XL file generated by running opcmigrate generate")
parser.add_argument("--inst_name",help="Match a particular name of an instance to create the secrets and hosts file")
parser.add_argument("--oci_config_file", help="the Oci config file - defaults to ~/.oci/config")

args = parser.parse_args()
tf_file = args.tfstatefile
opc_migrate_instance_export = args.koala_export_file
koala_resource_file = args.koala_resource_file
inst_name = args.inst_name
xl = args.xlfile
oci_conf_file = args.oci_config_file

xlfile =  pd.ExcelFile(xl)
DEBUG = ""

if not os.path.exists('tmp'):
    os.makedirs('tmp')

def write_file(file_name,file_data):
    f=open(file_name,"w+")
    f.write(file_data)
    f.close()

def append_file(file_name,file_data):
    f = open(file_name, "a")
    f.write(file_data)
    f.write("\n")
    f.close()



## Create the ocic-oci-sig bucket if it doesn't exist, then generate a Par for it.


config = ""
if oci_conf_file == None:
    config = oci.config.from_file()
else:
    config = oci.config.from_file(file_location=oci_conf_file)
compartment_id = config['vm_compartment_ocid']
print "Compartment_Id " + compartment_id
stg_object_store_bucket = "ocic-oci-sig"
object_stg_client = ObjectStorageClient(config)
bucket_details = oci.object_storage.models.CreateBucketDetails(name=stg_object_store_bucket,compartment_id=compartment_id)
bucket = None
namespace = object_stg_client.get_namespace().data
print "Namespace " + str(namespace)
try:

        bucket = object_stg_client.create_bucket(namespace_name=namespace,create_bucket_details=bucket_details)
        print "Creating Bucket - " + stg_object_store_bucket
#       print bucket.data
except oci.exceptions.ServiceError as e:
        if e.code == "BucketAlreadyExists":
                print "Bucket " + stg_object_store_bucket + " already exists - not creating it"
        else:
                print "############## ERRROR CREATING BUCKET #####################"
                print e.args[0]
par_uri = ""
try:

    date_now = datetime.datetime.utcnow()

    date_90 = date_now + datetime.timedelta(days=+90)
    date_90 = date_90.isoformat("T") + "Z"
    cprd = CreatePreauthenticatedRequestDetails(name="OCIC2OIC",object_name=None,access_type="AnyObjectWrite",time_expires=date_90)
    response = object_stg_client.create_preauthenticated_request(namespace,stg_object_store_bucket,cprd)
    par_uri = response.data.access_uri

except oci.exceptions.ServiceError as e:
    print e.args[0]



## OCIC Info

ocic_values = {}

with open(tf_file,'r') as json_file:
    data = json.load(json_file)
#    for d in data['modules']:
    for o in data['outputs']:
        if DEBUG.lower() == "debug":
            print o + " = " + data['outputs'][o]['value']
        ocic_values[o] = data['outputs'][o]['value'].strip()

json_file.close()

ocic_hosts = ""
instance_export_host_map = {}



count = 0
with open(opc_migrate_instance_export, 'r') as js_file:
    data = json.load(js_file)
    for i in data['instances']:
        hostname = i['name'].rsplit("/")[-2]
        if DEBUG.lower() == "debug":
            print i['name']
        if inst_name != None:
            if inst_name in hostname:
                data = """  - {name: \"""" + i['name'] + "\", os: \"" + i['os'] + "\", osSku: \"" + i['osSku'] + """\", attached_only: "false" }""" + "\n"
                #ocic_hosts = ocic_hosts + """  - name: \"""" + i['name'] + "\", os: \"" + i['os'] + "\", osSku: \"" + i['osSku'] + """\", attached_only: "false" }""" + "\n"
                ocic_hosts = ocic_hosts + data
                instance_export_host_map[hostname] = data
        else:
            data = """  - {name: \"""" + i['name'] + "\", os: \"" + i['os'] + "\", osSku: \"" + i['osSku'] + """\", attached_only: "false" }""" + "\n"
            # ocic_hosts = ocic_hosts + """  - name: \"""" + i['name'] + "\", os: \"" + i['os'] + "\", osSku: \"" + i['osSku'] + """\", attached_only: "false" }""" + "\n"
            ocic_hosts = ocic_hosts + data
            instance_export_host_map[hostname] = data
        count = count + 1
js_file.close()
# print "Count from instance export " + str(count)

if DEBUG.lower() == "debug":
    print "OCIC Keys " + str(ocic_values.keys())
    print "OCIC Values" + str(ocic_values.values())


## Read the OCI Config file @ ~/.oci/config


#config = configparser.RawConfigParser()
#config.read(oci_conf_file)
# config.sections()

i = 0
write = 1
secrets_file_prefix = "tmp/generated-secrets"
if write == 1:
    print "Generating Secrets file in tmp directory \n"
    for ins in instance_export_host_map:
        secrets_file = secrets_file_prefix + "-" + ins + ".yml"

        region = config['region']
        write_file(secrets_file, "#OCI Info\n")
        append_file(secrets_file, "compartment_id: " + config['vm_compartment_ocid'])
        # append_file(secrets_file, "compartment_name: " + config['compartment_name'])
        append_file(secrets_file, "user_id: " + config['user'])
        append_file(secrets_file, "fingerprint: " + config['fingerprint'])
        append_file(secrets_file, "tenancy_id: " + config['tenancy'])
        append_file(secrets_file, "region: " + region)
        append_file(secrets_file, "availability_domain: " + config['ad_1'])
        #Control-T version and shape data.
        ctlt_vers_shape_data = """
# version and shape used to the Control-T instance
# 'Oracle Linux' is the only supported operating_system
oracle_linux_version: '7.6'
shape: 'VM.Standard2.1'
"""
        append_file(secrets_file,ctlt_vers_shape_data)
        append_file(secrets_file, "subnet_id: " + config['ocs_subnet_ocid'])
        append_file(secrets_file, "pass_phrase: ")
        append_file(secrets_file, "ocic_oci_sig_par: https://objectstorage." + region + ".oraclecloud.com" + par_uri)

        append_file(secrets_file,"\n\n# OCI-C info \n")
        endpoint = ocic_values['endpoint']
        endpoint = endpoint.replace("https://","")

        append_file(secrets_file,"opc_profile_endpoint: " + endpoint)
        append_file(secrets_file,"opc_password: " + ocic_values['password'])
        append_file(secrets_file,"\n\n# Control-s Instance settings\n")
        append_file(secrets_file, "container: " + ocic_values['container'].strip() + "\n")
        append_file(secrets_file,"ctlsInstanceName: " + ocic_values['ctlsInstanceName'].strip()+ "\n")
        append_file(secrets_file,"targetControllerName: " + ocic_values['targetControllerName'].strip() + "\n")
        append_file(secrets_file,"targetControllerCores: 3 # change depending on server capacity\n")
        append_file(secrets_file,"targetControllerAvailableDiskSlots: 3 # change depending on capacity\n")
        append_file(secrets_file,"targetControllerAvailableStorageInGB: 2048\n")
        ocic_file_static="""
workerThreadCount: 10 # The number of worker threads working on volume migrations        
"""
        append_file(secrets_file,ocic_file_static + " \n")
        append_file(secrets_file,"# List of Instances\n")
        append_file(secrets_file,"instances: ")
        append_file(secrets_file,instance_export_host_map[ins])



### TO generate the hosts.yml file - need to get the Public IP / Private IP of each of the hosts
### For this phase lets consider just the public IP.
### Also need to find out what IP Address is associated with the instance and go from there - so it is a bit of craziness.

instance_sheet = xlfile.parse("instance")
js = instance_sheet.get("attributes")
count = 0
ip_address = ""
hostname =""
full_instance = ""
xl_host_ip_map = {}
for j in js:
    try:
        j = str(j).replace("'", "\"")
        j = j.replace("True","\"True\"")
        jso = json.loads(j)

        for x in range(0, 8):
            try:
                # print "IP Address: " + ip_address
                nimbula_str='nimbula_vcable-eth'+str(x)
                ip_address = str(jso['network'][nimbula_str]['address'][1])
                full_instance = jso['network'][nimbula_str]['instance']
                break
            except Exception as e:
                continue
        if(x==7):
            #print "Nimbula not found, trying oracle_metadata"
            full_instance = "shared_" + jso['oracle_metadata']['v1']['object']

        #print "Instance: " + hostname
        hostname = full_instance.rsplit("/")[-2]
        #xl_host_ip_map[hostname] = {ip_address: full_instance}
        xl_host_ip_map[hostname] = {}
        xl_host_ip_map[hostname]["ip"] = ip_address
        xl_host_ip_map[hostname]["full_instance"] = full_instance
        count = count +1
    except Exception as e:

        if ("Mapping" in e.__doc__):
            print "both nimbula and oracle_metadata not found. Ignoring"
            #print "Mapping Key not found - ignoring\n"
        else:
            print e.__doc__
            print e.message
            print j
        continue
# print "Total Count of Instances from XL sheet: " + str(count)
## We now have the data from two sources, the Koala file and the XL sheet.  Put it together
## for generating hosts.yml.
## instance_export_host_map & xl_host_ip_map should match up to give us the right data.

print "Generating hosts file in tmp directory "
hosts_yml_file_prefix = "tmp/generated-hosts-"
hosts_yml_file_single = "tmp/generated-all-hosts.yml"
write_file(hosts_yml_file_single,"##OCIC Info\n\n")

for i in instance_export_host_map:
    hosts_data = """source:
  hosts:
    """ + xl_host_ip_map[i]["ip"] + """: 
      label: """ + i
    data = instance_export_host_map[i]
    if "linux" in data:
        hosts_data = hosts_data + """
      remote_user: opc
      ansible_ssh_private_key_file: ~/.ssh/id_rsa
      ansible_python_interpreter: /usr/bin/python
"""
    hosts_yml_file = hosts_yml_file_prefix + "-" + i + ".yml"
    write_file(hosts_yml_file, hosts_data)
    append_file(hosts_yml_file_single,hosts_data)



